{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Product recommendation with Google Tensorflow \n",
        "#### Dataset download > \n",
        "* #### [Instacart](https://www.kaggle.com/c/instacart-market-basket-analysis)\n",
        "\n",
        "#### Concepts, tools, libraries used >\n",
        "* #### [Wide & Deep](https://ai.googleblog.com/2016/06/wide-deep-learning-better-together-with.html)\n",
        "* #### [Tensorflow](https://www.tensorflow.org/)\n",
        "* #### [Petastorm](https://github.com/uber/petastorm)\n",
        "* #### [Hyperopt](https://github.com/hyperopt/hyperopt)\n",
        "* #### [MLFlow](https://mlflow.org/)\n",
        "\n",
        "This is a series of three notebooks. This is notebook #1. The purpose of this notebook is to prepare the dataset we will use to build a \"Wide & Deep\" collaborative filter recommender.  \n",
        "This notebook was run on Azure Synapse."
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "a31b69ac-94f3-4d37-9c55-1fadd1049d8c"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction \n",
        "\n",
        "Collaborative filters leverage similarities between users to make recommendations:\n",
        "\n",
        "<img src=\"https://brysmiwasb.blob.core.windows.net/demos/images/instacart_collabrecom.png\" width=\"600\">\n",
        "\n",
        "Unlike with memory-based collaborative filters which employ the weighted averaging of product ratings (explicit or implied) between similar users, model-based collaborative filters leverage the features associated with user-product combinations to predict that a given user will click-on or purchase a particular item.  To build such a model, we will need information about users and the products they have purchased."
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "cc5c3c39-13a0-46d9-a5d9-699e72f5cc5b"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import *\n",
        "import pyspark.sql.functions as f\n",
        "from pyspark.sql import window as w "
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": null,
              "session_id": null,
              "statement_id": null,
              "state": "cancelled",
              "livy_statement_state": null,
              "queued_time": "2022-06-25T07:24:53.7129051Z",
              "session_start_time": "2022-06-25T07:24:53.7498841Z",
              "execution_start_time": null,
              "execution_finish_time": "2022-06-25T07:25:05.6163356Z"
            },
            "text/plain": "StatementMeta(, , , Cancelled, )"
          },
          "metadata": {}
        }
      ],
      "execution_count": 1,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "Import Required Libraries",
          "showTitle": true,
          "inputWidgets": {},
          "nuid": "8a90bb8d-d0e0-40e5-a178-2736cf06b844"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reading csv files in a dataframe\r\n",
        "file_path = \"abfss://recommender@salabcommercedatalake.dfs.core.windows.net/instacart/bronze/aisles/aisles.csv\"\r\n",
        "df = spark.read.csv(file_path, header=True, inferSchema=True)\r\n",
        "display(df.limit(10))"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": null,
              "session_id": null,
              "statement_id": null,
              "state": "cancelled",
              "livy_statement_state": null,
              "queued_time": "2022-06-25T07:24:53.7141476Z",
              "session_start_time": null,
              "execution_start_time": null,
              "execution_finish_time": "2022-06-25T07:25:05.6113472Z"
            },
            "text/plain": "StatementMeta(, , , Cancelled, )"
          },
          "metadata": {}
        }
      ],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1: Load the Data\n",
        "\n",
        "The basic building block of the collaborative filter is transactional data containing a customer identifier. The popular [Instacart dataset](https://www.kaggle.com/c/instacart-market-basket-analysis) provides us a nice collection of such data with over 3 million grocery orders placed by over 200,000 Instacart users over a nearly 2-year period across of portfolio of nearly 50,000 products. \n",
        "\n",
        "**NOTE** Due to the terms and conditions by which these data are made available, anyone interested in recreating this work will need to download the data files from Kaggle and upload them to a folder structure as described below.\n",
        "\n",
        "The primary data files available for download are organized as follows under a pre-defined [mount point](https://docs.databricks.com/data/databricks-file-system.html#mount-object-storage-to-dbfs) that we have named */mnt/instacart*:\n",
        "\n",
        "<img src='https://brysmiwasb.blob.core.windows.net/demos/images/instacart_filedownloads.png' width=250>\n",
        "\n",
        "\n",
        "\n",
        "Read into dataframes, these files form the following data model which captures the products customers have included in individual transactions:\n",
        "\n",
        "<img src='https://brysmiwasb.blob.core.windows.net/demos/images/instacart_schema2.png' width=300>\n",
        "\n",
        "We will apply minimal transformations to this data, persisting it to the Delta Lake format for speedier access:"
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "8e8ca031-4399-4a93-a9cd-4f6183415b92"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "_ = spark.sql('CREATE DATABASE IF NOT EXISTS instacart')"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": null,
              "session_id": null,
              "statement_id": null,
              "state": "cancelled",
              "livy_statement_state": null,
              "queued_time": "2022-06-25T07:24:53.7155518Z",
              "session_start_time": null,
              "execution_start_time": null,
              "execution_finish_time": "2022-06-25T07:25:05.6121794Z"
            },
            "text/plain": "StatementMeta(, , , Cancelled, )"
          },
          "metadata": {}
        }
      ],
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "Create Database",
          "showTitle": true,
          "inputWidgets": {},
          "nuid": "74260186-6eeb-415e-9d8a-46035f29188b"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The orders data is pre-divided into *prior* and *training* evaluation sets, where the *training* dataset represents the last order placed in the overall sequence of orders associated with a given customer.  The *prior* dataset represents those orders that proceed the *training* order.  In a previous set of notebooks built on this data, we relabeled the *prior* and *training* evaluation sets as *calibration* and *evaluation*, respectively, to better align terminology with how the data was being used.  Here, we will preserve the *prior* & *training* designations as this better aligns with our current modeling needs.\n",
        "\n",
        "We will add to this dataset a field, *days_prior_to_last_order*, which calculates the days from a given order to the order that represents the *training* instance. This field will help us when developing features around purchases taking place different intervals prior to the final order.  All other tables will be brought into the database without schema changes, simply converting the underlying format from CSV to delta lake for better query performance later:"
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "6be6b60d-396d-47b2-979f-2ef972ddf2ad"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# delete the old table if needed\n",
        "_ = spark.sql('DROP TABLE IF EXISTS instacart.orders')\n",
        "\n",
        "# define schema for incoming data\n",
        "orders_schema = StructType([\n",
        "  StructField('order_id', IntegerType()),\n",
        "  StructField('user_id', IntegerType()),\n",
        "  StructField('eval_set', StringType()),\n",
        "  StructField('order_number', IntegerType()),\n",
        "  StructField('order_dow', IntegerType()),\n",
        "  StructField('order_hour_of_day', IntegerType()),\n",
        "  StructField('days_since_prior_order', FloatType())\n",
        "  ])\n",
        "\n",
        "# read data from csv\n",
        "orders = (\n",
        "  spark\n",
        "    .read\n",
        "    .csv(\n",
        "      'abfss://recommender@salabcommercedatalake.dfs.core.windows.net/instacart/bronze/orders',\n",
        "      header=True,\n",
        "      schema=orders_schema\n",
        "      )\n",
        "  )\n",
        "\n",
        "# calculate days until final purchase \n",
        "win = (\n",
        "  w.Window.partitionBy('user_id').orderBy(f.col('order_number').desc())\n",
        "  )\n",
        "\n",
        "orders_enhanced = (\n",
        "    orders\n",
        "      .withColumn(\n",
        "        'days_prior_to_last_order', \n",
        "        f.sum('days_since_prior_order').over(win) - f.coalesce(f.col('days_since_prior_order'),f.lit(0))\n",
        "        ) \n",
        "  )\n",
        "\n",
        "# write data to delta\n",
        "(\n",
        "  orders_enhanced\n",
        "    .write\n",
        "    .format('delta')\n",
        "    .mode('overwrite')\n",
        "    .option('overwriteSchema','true')\n",
        "    .save('abfss://recommender@salabcommercedatalake.dfs.core.windows.net/instacart/silver/orders')\n",
        "  )\n",
        "\n",
        "# make accessible as spark sql table\n",
        "_ = spark.sql('''\n",
        "  CREATE TABLE instacart.orders\n",
        "  USING DELTA\n",
        "  LOCATION 'abfss://recommender@salabcommercedatalake.dfs.core.windows.net/instacart/silver/orders'\n",
        "  ''')\n",
        "\n",
        "# present the data for review\n",
        "display(\n",
        "  spark\n",
        "    .table('instacart.orders')\n",
        "    .orderBy('user_id','order_number')\n",
        "    .limit(10)\n",
        "  )"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": null,
              "session_id": null,
              "statement_id": null,
              "state": "cancelled",
              "livy_statement_state": null,
              "queued_time": "2022-06-25T07:24:53.7171676Z",
              "session_start_time": null,
              "execution_start_time": null,
              "execution_finish_time": "2022-06-25T07:25:05.6128456Z"
            },
            "text/plain": "StatementMeta(, , , Cancelled, )"
          },
          "metadata": {}
        }
      ],
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "Orders",
          "showTitle": true,
          "inputWidgets": {},
          "nuid": "b3f752ca-b326-44c2-b7a6-9fb6276517df"
        },
        "collapsed": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# delete the old table if needed\n",
        "_ = spark.sql('DROP TABLE IF EXISTS instacart.products')\n",
        "\n",
        "# define schema for incoming data\n",
        "products_schema = StructType([\n",
        "  StructField('product_id', IntegerType()),\n",
        "  StructField('product_name', StringType()),\n",
        "  StructField('aisle_id', IntegerType()),\n",
        "  StructField('department_id', IntegerType())\n",
        "  ])\n",
        "\n",
        "# read data from csv\n",
        "products = (\n",
        "  spark\n",
        "    .read\n",
        "    .csv(\n",
        "     'abfss://recommender@salabcommercedatalake.dfs.core.windows.net/instacart/bronze/products',\n",
        "      header=True,\n",
        "      schema=products_schema\n",
        "      )\n",
        "  )\n",
        "\n",
        "# write data to delta\n",
        "(\n",
        "  products\n",
        "    .write\n",
        "    .format('delta')\n",
        "    .mode('overwrite')\n",
        "    .option('overwriteSchema','true')\n",
        "    .save('abfss://recommender@salabcommercedatalake.dfs.core.windows.net/instacart/silver/products')\n",
        "  )\n",
        "\n",
        "# make accessible as spark sql table\n",
        "_ = spark.sql('''\n",
        "  CREATE TABLE instacart.products\n",
        "  USING DELTA\n",
        "  LOCATION 'abfss://recommender@salabcommercedatalake.dfs.core.windows.net/instacart/silver/products'\n",
        "  ''')\n",
        "\n",
        "# present the data for review\n",
        "display(\n",
        "  spark.table('instacart.products').limit(10)\n",
        "  )"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": null,
              "session_id": null,
              "statement_id": null,
              "state": "cancelled",
              "livy_statement_state": null,
              "queued_time": "2022-06-25T07:24:53.7186165Z",
              "session_start_time": null,
              "execution_start_time": null,
              "execution_finish_time": "2022-06-25T07:25:05.6134299Z"
            },
            "text/plain": "StatementMeta(, , , Cancelled, )"
          },
          "metadata": {}
        }
      ],
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "Products",
          "showTitle": true,
          "inputWidgets": {},
          "nuid": "38ee2b03-caba-48e1-9c0f-46a8b16b9a9b"
        },
        "collapsed": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# delete the old table if needed\n",
        "_ = spark.sql('DROP TABLE IF EXISTS instacart.order_products')\n",
        "\n",
        "# define schema for incoming data\n",
        "order_products_schema = StructType([\n",
        "  StructField('order_id', IntegerType()),\n",
        "  StructField('product_id', IntegerType()),\n",
        "  StructField('add_to_cart_order', IntegerType()),\n",
        "  StructField('reordered', IntegerType())\n",
        "  ])\n",
        "\n",
        "# read data from csv\n",
        "order_products = (\n",
        "  spark\n",
        "    .read\n",
        "    .csv(\n",
        "      'abfss://recommender@salabcommercedatalake.dfs.core.windows.net/instacart/bronze/order_products',\n",
        "      header=True,\n",
        "      schema=order_products_schema\n",
        "      )\n",
        "  )\n",
        "\n",
        "# write data to delta\n",
        "(\n",
        "  order_products\n",
        "    .write\n",
        "    .format('delta')\n",
        "    .mode('overwrite')\n",
        "    .option('overwriteSchema','true')\n",
        "    .save('abfss://recommender@salabcommercedatalake.dfs.core.windows.net/instacart/silver/order_products')\n",
        "  )\n",
        "\n",
        "# make accessible as spark sql table\n",
        "_ = spark.sql('''\n",
        "  CREATE TABLE instacart.order_products\n",
        "  USING DELTA\n",
        "  LOCATION 'abfss://recommender@salabcommercedatalake.dfs.core.windows.net/instacart/silver/order_products'\n",
        "  ''')\n",
        "\n",
        "# present the data for review\n",
        "display(\n",
        "  spark.table('instacart.order_products').limit(10)\n",
        "  )"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": null,
              "session_id": null,
              "statement_id": null,
              "state": "cancelled",
              "livy_statement_state": null,
              "queued_time": "2022-06-25T07:24:53.7207377Z",
              "session_start_time": null,
              "execution_start_time": null,
              "execution_finish_time": "2022-06-25T07:25:05.6140153Z"
            },
            "text/plain": "StatementMeta(, , , Cancelled, )"
          },
          "metadata": {}
        }
      ],
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "Order Products",
          "showTitle": true,
          "inputWidgets": {},
          "nuid": "5322e224-1ff7-4c32-bc35-96477725436a"
        },
        "collapsed": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# delete the old table if needed\n",
        "_ = spark.sql('DROP TABLE IF EXISTS instacart.departments')\n",
        "\n",
        "# define schema for incoming data\n",
        "departments_schema = StructType([\n",
        "  StructField('department_id', IntegerType()),\n",
        "  StructField('department', StringType())  \n",
        "  ])\n",
        "\n",
        "# read data from csv\n",
        "departments = (\n",
        "  spark\n",
        "    .read\n",
        "    .csv(\n",
        "      'abfss://recommender@salabcommercedatalake.dfs.core.windows.net/instacart/bronze/departments',\n",
        "      header=True,\n",
        "      schema=departments_schema\n",
        "      )\n",
        "  )\n",
        "\n",
        "# write data to delta\n",
        "(\n",
        "  departments\n",
        "    .write\n",
        "    .format('delta')\n",
        "    .mode('overwrite')\n",
        "    .option('overwriteSchema','true')\n",
        "    .save('abfss://recommender@salabcommercedatalake.dfs.core.windows.net/instacart/silver/departments')\n",
        "  )\n",
        "\n",
        "# make accessible as spark sql table\n",
        "_ = spark.sql('''\n",
        "  CREATE TABLE instacart.departments\n",
        "  USING DELTA\n",
        "  LOCATION 'abfss://recommender@salabcommercedatalake.dfs.core.windows.net/instacart/silver/departments'\n",
        "  ''')\n",
        "\n",
        "# present the data for review\n",
        "display(\n",
        "  spark.table('instacart.departments').limit(10)\n",
        "  )"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": null,
              "session_id": null,
              "statement_id": null,
              "state": "cancelled",
              "livy_statement_state": null,
              "queued_time": "2022-06-25T07:24:53.722508Z",
              "session_start_time": null,
              "execution_start_time": null,
              "execution_finish_time": "2022-06-25T07:25:05.6145628Z"
            },
            "text/plain": "StatementMeta(, , , Cancelled, )"
          },
          "metadata": {}
        }
      ],
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "Departments",
          "showTitle": true,
          "inputWidgets": {},
          "nuid": "f74e60aa-c172-477c-a3bd-1da5a378df56"
        },
        "collapsed": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# delete the old table if needed\n",
        "_ = spark.sql('DROP TABLE IF EXISTS instacart.aisles')\n",
        "\n",
        "# define schema for incoming data\n",
        "aisles_schema = StructType([\n",
        "  StructField('aisle_id', IntegerType()),\n",
        "  StructField('aisle', StringType())  \n",
        "  ])\n",
        "\n",
        "# read data from csv\n",
        "aisles = (\n",
        "  spark\n",
        "    .read\n",
        "    .csv(\n",
        "      'abfss://recommender@salabcommercedatalake.dfs.core.windows.net/instacart/bronze/aisles',\n",
        "      header=True,\n",
        "      schema=aisles_schema\n",
        "      )\n",
        "  )\n",
        "\n",
        "# write data to delta\n",
        "(\n",
        "  aisles\n",
        "    .write\n",
        "    .format('delta')\n",
        "    .mode('overwrite')\n",
        "    .option('overwriteSchema','true')\n",
        "    .save('abfss://recommender@salabcommercedatalake.dfs.core.windows.net/instacart/silver/aisles')\n",
        "  )\n",
        "\n",
        "# make accessible as spark sql table\n",
        "_ = spark.sql('''\n",
        "  CREATE TABLE instacart.aisles\n",
        "  USING DELTA\n",
        "  LOCATION 'abfss://recommender@salabcommercedatalake.dfs.core.windows.net/instacart/silver/aisles'\n",
        "  ''')\n",
        "\n",
        "# present the data for review\n",
        "display(\n",
        "  spark.table('instacart.aisles').limit(10)\n",
        "  )"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": null,
              "session_id": null,
              "statement_id": null,
              "state": "cancelled",
              "livy_statement_state": null,
              "queued_time": "2022-06-25T07:24:53.7248051Z",
              "session_start_time": null,
              "execution_start_time": null,
              "execution_finish_time": "2022-06-25T07:25:05.615081Z"
            },
            "text/plain": "StatementMeta(, , , Cancelled, )"
          },
          "metadata": {}
        }
      ],
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "Aisles",
          "showTitle": true,
          "inputWidgets": {},
          "nuid": "b9fa5946-979c-414e-9eac-643443682611"
        },
        "collapsed": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2: Combine Order Details\n",
        "\n",
        "With our data loaded, we will flatten our order details through a view.  This will make access to our data during feature engineering significantly easier:"
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "385f89f1-0c9d-45d8-a1c3-ae54b9426dc0"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%sql\n",
        "DROP VIEW IF EXISTS instacart.order_details;\n",
        "\n",
        "CREATE VIEW instacart.order_details as\n",
        "  SELECT\n",
        "    a.eval_set,\n",
        "    a.user_id,\n",
        "    a.order_number,\n",
        "    a.order_id,\n",
        "    a.order_dow,\n",
        "    a.order_hour_of_day,\n",
        "    a.days_since_prior_order,\n",
        "    a.days_prior_to_last_order,\n",
        "    b.product_id,\n",
        "    c.aisle_id,\n",
        "    c.department_id,\n",
        "    b.reordered\n",
        "  FROM instacart.orders a\n",
        "  INNER JOIN instacart.order_products b\n",
        "    ON a.order_id=b.order_id\n",
        "  INNER JOIN instacart.products c\n",
        "    ON b.product_id=c.product_id;\n",
        "    \n",
        "SELECT *\n",
        "FROM instacart.order_details;"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": null,
              "session_id": null,
              "statement_id": null,
              "state": "cancelled",
              "livy_statement_state": null,
              "queued_time": "2022-06-25T07:24:53.7321559Z",
              "session_start_time": null,
              "execution_start_time": null,
              "execution_finish_time": "2022-06-25T07:25:05.6156795Z"
            },
            "text/plain": "StatementMeta(, , , Cancelled, )"
          },
          "metadata": {}
        }
      ],
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "a5439d54-43a2-4332-9f0a-15ab874838a6"
        },
        "microsoft": {
          "language": "sparksql"
        },
        "collapsed": false
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "synapse_pyspark",
      "display_name": "Synapse PySpark"
    },
    "language_info": {
      "name": "python"
    },
    "description": null,
    "save_output": true,
    "synapse_widget": {
      "version": "0.1",
      "state": {}
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}